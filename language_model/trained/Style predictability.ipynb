{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BERT to quantify the predictability of writing style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer-based models of language such as BERT have been used create state-of-the-art models for a wide range of NLP tasks over the past few years. \n",
    "BERT's next-sentence prediction's capability have recently been used to <a href='https://tedunderwood.com/2020/07/05/how-predictable-is-fiction/'>assess the predictability of fiction.</a> \n",
    "This notebook attempts to use another task that BERT can be trained on, masked language modeling, to assess the predictability of style within a single sentence.\n",
    "\n",
    "In lay language, Masked language modeling can be described as a fill-in-the-blanks task. A model is given a sentence, each token in the sentence is hidden and the model made to predict it using the surrounding context words. The idea is that we can use the probability generated by such a model to assess how predictable the style of a sentence is. For instance, using English as an example, in the following sentence:\n",
    "\n",
    "    His hair as gold as the sun , his eyes blue like the [MASK].\n",
    "\n",
    "BERT (English) can predict `sky` with a 27.1% probability. But in the this sentence:\n",
    "\n",
    "    `The [MASK] above the port was the color of television, tuned to a dead channel`\n",
    "\n",
    "the probability of `sky` falls much lower, with BERT instead giving tokens such as `screen`, `window` or `panel` the highest probabilities. In short, BERT can predict trite comparisons much better than creative ones. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "I would like to extend this beyond the simple scope of comparison, from a single word to the scale of a complete sentence, in order to evaluate that sentence's predictability. This is possible because BERT's probability would assess a couple of things typically associated with literary creativity: \n",
    "- the \"preciosity\" of a word (given two synonyms, the rarer one will receive a lower probability)\n",
    "- the unexpectedness of comparison and language (we might say that BERT's probabilities are computed following paradigmatic (predicting a word over others) and syntagmatic (based on its context) axes, whose order are subverted by literary language)\n",
    "\n",
    "The predictability score could then be used as a proxy value for literary creativity. Being able to quantify such a value would be interesting for literary history and comparative literature because it would create a metric of creativity to compare against signs of literary recognition, enabling us to evaluate how much a certain literary culture values conformity over creativity (and vice-versa).\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "The insight that a language model can be used to assert how \"common\" the style of sentence is not entirely new. The scoring of sentences by language models, knowng as <a href='https://en.wikipedia.org/wiki/Perplexity#:~:text=of%20size%20N).-,Perplexity%20per%20word,over%20entire%20sentences%20or%20texts.'>perplexity</a> has been used in task such as automatic translation to rate which of the outputs of a model might be the most well-formed sentence in particular target language. The main differences with our case are that:\n",
    "1. Traditional language models are sequential, working from left to right, rather than the with the whole sentence as a context.\n",
    "2. Working with literary texts, we can assume that the sentences we will feed into the model will be generally gramatically correct.\n",
    "\n",
    "Regarding point 1, BERT gives us an advantage over sequential language models. Because it is bi-directional, it allows us to consider the context on both sides of a word, which is closer to how a human reader would assert the unexpectedness of a single word. One <a href=' https://arxiv.org/pdf/1906.00363.pdf'>paper</a> thus averaged the probabilities of the tokens in a sentence ($\\prod_{i=1}^{n}p(w_{i}|w_{1},...,w_{i-1},w_{i+1},...,w_{n}))^{-1/n} $) to predict whether a sentence is non-sensical or not - similar to how the perplexity score is used by traditional language models.\n",
    "\n",
    "Point 2 is tied to language specific issues, adressed below.\n",
    "\n",
    "### Language specifics\n",
    "\n",
    "Working with Korean and with literary texts, the above formula does present some limitations. For instance, Korean can mark the object of a verb with a specific particle (를/을). Predicting this particle being present between a noun and a verb is not hard (tokenizers such as BERT's separate it from the noun to which it would be attached). Therefore the token would be assigned a high probability. However, case particles can and are often omitted depending on context and individual preferences. Including it in the scoring of a sentence might therefore introduce bias, ranking writers who use it extensively as less creative than writers who use it more sparingly. On the other hand, as noted in Point 2 above, we are not interested in evaluating the grammatical correctness of a sentence, and therefore including case particles bring little additional information to our metric. The same is true of punctuation, pronouns, prepositions... We therefore opt to restrict the model to predicting masked nouns, adjectives and verbs (all tokens are still nonetheless used as context).\n",
    "\n",
    "### Technical specifics\n",
    "\n",
    "This approach requires us to be able to control the tokenization process because we want to be able to select the words which we will mask for prediction. This is more complex than it seems, because most implementations of BERT uses a type of tokenizer that works splitting more complex words into smaller words to retain a small vocabulary size. This choice of tokenizing method is a powerful way to deal with out-of-vocabulary words (they will be split into smaller, in-vocabulary pieces). \n",
    "\n",
    "To address this issue, I've pre-tokenized the training data used during fine-tuning. I then train a new tokenizer with a large dictionary size and use its vocabulary to update the tokenizer's vocabulary of the base BERT model used for fine-tuning. (see <a href='https://github.com/digitalprk/sih_notebooks/blob/master/run_language_modeling.py'>here</a>).\n",
    "\n",
    "The base model used was <a href='https://github.com/SKTBrain/KoBERT'>KoBERT</a>, a BERT model trained by the SK Telecom team on South Korean language data. The model was fine-tuned on a small (1.6Gb) corpus of North Korean language data comprising novels, literary journals, newspapers, non-fiction books and the complete works of Kim Il-Sung and Kim Jong-Il.\n",
    "\n",
    "### Data\n",
    "\n",
    "Sentences were extracted from four types of sources:\n",
    "1. The Korean Central News Agency (the North Korean state's press agency)\n",
    "2. Novels by prestigious writers (recognized for their literary excellence with a state sanctioned distinction)\n",
    "3. Novels by \"regular\" writers\n",
    "4. Canonical novels (fictional accounts of the lives of Kim Il-Sung and Kim Jong-Il held to be of the highest literary quality). \n",
    "\n",
    "None of the novels or press releases used were present in the corpus used to fine-tune the model. However, the corpus did contain similar content (literary sources and press releases for different years).\n",
    "\n",
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x253a43f4408>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df.boxplot(figsize = (15, 10), showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean Central News Agency : Prestigious Novels\n",
      "Ttest_indResult(statistic=-1.9925895746961764, pvalue=0.04633354914603183)\n",
      "Korean Central News Agency : Regular Novels\n",
      "Ttest_indResult(statistic=-0.19871218920210995, pvalue=0.8424919290229935)\n",
      "Korean Central News Agency : Canonical Novels\n",
      "Ttest_indResult(statistic=-2.285899975225016, pvalue=0.022280935649715887)\n",
      "Prestigious Novels : Regular Novels\n",
      "Ttest_indResult(statistic=1.6062157018139056, pvalue=0.10825810476960021)\n",
      "Prestigious Novels : Canonical Novels\n",
      "Ttest_indResult(statistic=0.02962811881368405, pvalue=0.9763642309487608)\n",
      "Regular Novels : Canonical Novels\n",
      "Ttest_indResult(statistic=-1.7660209785665917, pvalue=0.07742284297112875)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "for a, b in list(combinations(df.columns, 2)):\n",
    "    print(f'{a} : {b}')\n",
    "    print(stats.ttest_ind(df[a],df[b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Intepretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0921 21:17:51.718943 49680 file_utils.py:39] PyTorch version 1.6.0 available.\n",
      "I0921 21:17:56.186017 49680 file_utils.py:55] TensorFlow version 2.2.0 available.\n",
      "I0921 21:17:57.334977 49680 configuration_utils.py:262] loading configuration file ./jobert\\config.json\n",
      "I0921 21:17:57.335977 49680 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 20839\n",
      "}\n",
      "\n",
      "I0921 21:17:57.336944 49680 tokenization_utils_base.py:1167] Model name './jobert' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming './jobert' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0921 21:17:57.338938 49680 tokenization_utils_base.py:1197] Didn't find file ./jobert\\added_tokens.json. We won't load it.\n",
      "I0921 21:17:57.339967 49680 tokenization_utils_base.py:1197] Didn't find file ./jobert\\tokenizer.json. We won't load it.\n",
      "I0921 21:17:57.340933 49680 tokenization_utils_base.py:1252] loading file ./jobert\\vocab.txt\n",
      "I0921 21:17:57.341931 49680 tokenization_utils_base.py:1252] loading file None\n",
      "I0921 21:17:57.341931 49680 tokenization_utils_base.py:1252] loading file ./jobert\\special_tokens_map.json\n",
      "I0921 21:17:57.342927 49680 tokenization_utils_base.py:1252] loading file ./jobert\\tokenizer_config.json\n",
      "I0921 21:17:57.344923 49680 tokenization_utils_base.py:1252] loading file None\n",
      "C:\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\transformers\\modeling_auto.py:798: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "I0921 21:17:57.383817 49680 configuration_utils.py:262] loading configuration file ./jobert\\config.json\n",
      "I0921 21:17:57.384816 49680 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 20839\n",
      "}\n",
      "\n",
      "I0921 21:17:57.386810 49680 modeling_utils.py:665] loading weights file ./jobert\\pytorch_model.bin\n",
      "I0921 21:18:03.531785 49680 modeling_utils.py:765] All model checkpoint weights were used when initializing BertForMaskedLM.\n",
      "\n",
      "I0921 21:18:03.532782 49680 modeling_utils.py:774] All the weights of BertForMaskedLM were initialized from the model checkpoint at ./jobert.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./jobert\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"./jobert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_word_proba(sequence, word):\n",
    "    global model, tokenizer\n",
    "    input_ids = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "    mask_token_index = torch.where(input_ids == tokenizer.mask_token_id)[1]\n",
    "    token_logits = model(input_ids)[0]\n",
    "    mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "    mask_token_logits = torch.softmax(mask_token_logits, dim=1)\n",
    "    sought_after_token = word\n",
    "    sought_after_token_id = tokenizer.encode(sought_after_token, add_special_tokens=False, add_prefix_space=True)[0]\n",
    "    token_score = mask_token_logits[:, sought_after_token_id]\n",
    "    return token_score.detach().numpy()[0]\n",
    "\n",
    "def compute_word_by_word_proba(sequence):\n",
    "    global tokenizer\n",
    "    global komoran\n",
    "    pos_filter = ['VV', 'VA', 'NNG', 'NNP', 'MAG', 'NA', 'SN', 'XR'] # we only want to predict verbs, nouns and adjectives\n",
    "    word_dict = {}\n",
    "    tokenized_sequence = komoran.pos(sequence)\n",
    "    sequence = ' '.join([token for token, pos in tokenized_sequence])\n",
    "    for token, pos in tokenized_sequence:\n",
    "        #print(token, pos)\n",
    "        if pos in pos_filter:\n",
    "            masked_sequence = sequence.replace(token, tokenizer.mask_token)\n",
    "            word_dict[token] = compute_word_proba(masked_sequence, token)\n",
    "    return word_dict\n",
    "\n",
    "def geometric_mean(series):\n",
    "    return np.array(series, dtype=np.float64).prod()**(1.0/len(series))\n",
    "\n",
    "def compute_sentence_score(sentence):\n",
    "    return geometric_mean(list(compute_word_by_word_proba(sentence).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kcna.txt\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "3250\n",
      "3300\n",
      "3350\n",
      "3400\n",
      "3450\n",
      "3500\n",
      "3550\n",
      "3600\n",
      "3650\n",
      "3700\n",
      "3750\n",
      "3800\n",
      "3850\n",
      "3900\n",
      "3950\n",
      "4000\n",
      "4050\n",
      "4100\n",
      "4150\n",
      "4200\n",
      "4250\n",
      "4300\n",
      "4350\n",
      "4400\n",
      "4450\n",
      "4500\n",
      "4550\n",
      "4600\n",
      "4650\n",
      "4700\n",
      "4750\n",
      "4800\n",
      "4850\n",
      "4900\n",
      "4950\n",
      "novels-415.txt\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "Error: ≪그가 무엇 때문에 여기에 왔지?\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "3250\n",
      "3300\n",
      "3350\n",
      "3400\n",
      "3450\n",
      "3500\n",
      "3550\n",
      "3600\n",
      "3650\n",
      "3700\n",
      "3750\n",
      "3800\n",
      "3850\n",
      "3900\n",
      "3950\n",
      "4000\n",
      "4050\n",
      "4100\n",
      "4150\n",
      "4200\n",
      "4250\n",
      "4300\n",
      "4350\n",
      "4400\n",
      "4450\n",
      "4500\n",
      "4550\n",
      "4600\n",
      "4650\n",
      "4700\n",
      "4750\n",
      "4800\n",
      "4850\n",
      "4900\n",
      "4950\n",
      "novels.txt\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "3250\n",
      "3300\n",
      "3350\n",
      "3400\n",
      "3450\n",
      "3500\n",
      "3550\n",
      "3600\n",
      "3650\n",
      "3700\n",
      "3750\n",
      "3800\n",
      "3850\n",
      "3900\n",
      "3950\n",
      "4000\n",
      "4050\n",
      "4100\n",
      "4150\n",
      "4200\n",
      "4250\n",
      "4300\n",
      "4350\n",
      "4400\n",
      "4450\n",
      "4500\n",
      "4550\n",
      "4600\n",
      "4650\n",
      "4700\n",
      "4750\n",
      "4800\n",
      "4850\n",
      "4900\n",
      "4950\n",
      "pulmyol.txt\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "3250\n",
      "3300\n",
      "3350\n",
      "3400\n",
      "3450\n",
      "3500\n",
      "3550\n",
      "3600\n",
      "3650\n",
      "3700\n",
      "3750\n",
      "3800\n",
      "3850\n",
      "3900\n",
      "3950\n",
      "4000\n",
      "4050\n",
      "4100\n",
      "4150\n",
      "4200\n",
      "4250\n",
      "4300\n",
      "4350\n",
      "4400\n",
      "4450\n",
      "4500\n",
      "4550\n",
      "4600\n",
      "4650\n",
      "4700\n",
      "4750\n",
      "4800\n",
      "4850\n",
      "4900\n",
      "4950\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/project/RDS-FASS-NKBert-RW/samples/final_scores.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-9f78843f4e9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mfinal_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/project/RDS-FASS-NKBert-RW/samples/final_scores.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/project/RDS-FASS-NKBert-RW/samples/final_scores.pkl'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "sample_data_path = './samples'\n",
    "sample_files = [file for file in os.listdir(sample_data_path) if not file.endswith('-tokenized.txt')]\n",
    "final_results = {}\n",
    "for file in sample_files:\n",
    "    with open(os.path.join(sample_data_path, file), 'r', encoding='utf8') as fp:\n",
    "        sentences = fp.read().splitlines()\n",
    "    scores = []\n",
    "    print(file)\n",
    "    for i, sentence in enumerate(sentences[:5000]):\n",
    "        if (i % 50) == 0:\n",
    "            print(i)\n",
    "        try:\n",
    "            score = compute_sentence_score(sentence.replace('\\xa0 ', ''))\n",
    "            scores.append(score)\n",
    "        except:\n",
    "            scores.append(np.mean(scores))\n",
    "            print(\"Error:\", sentence)\n",
    "            pass\n",
    "    \n",
    "    final_results[file] = scores\n",
    "    \n",
    "with open('/project/RDS-FASS-NKBert-RW/samples/final_scores.pkl', 'wb') as fp:\n",
    "    pickle.dump(final_results, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006593437362473346"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sentence_score('각도 건설 자 들 과 인민군 군인 들 은 지금 400 리 의 물길 파기 와 굴 뚫 기 구조물 공사 갑문 건설 을 힘 있 게 내밀 고 있 다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kcna.txt</th>\n",
       "      <th>novels-415.txt</th>\n",
       "      <th>novels.txt</th>\n",
       "      <th>pulmyol.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      kcna.txt  novels-415.txt  novels.txt  pulmyol.txt\n",
       "0     0.000181        0.000030    0.000079     0.000137\n",
       "1     0.000135        0.000111    0.000200     0.000369\n",
       "2     0.000354        0.000450    0.000109     0.000126\n",
       "3     0.000335        0.000226    0.000079     0.000076\n",
       "4     0.000132        0.000308    0.000136     0.000206\n",
       "...        ...             ...         ...          ...\n",
       "4995  0.000366        0.000141    0.000180     0.000254\n",
       "4996  0.000657        0.000132    0.000041     0.000344\n",
       "4997  0.000126        0.000085    0.000089     0.000141\n",
       "4998  0.000209        0.000220    0.000156     0.000166\n",
       "4999  0.000178        0.000195    0.000726     0.000146\n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(final_results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x253a3878348>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df.boxplot(figsize = (20, 10), showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.6062157018139056, pvalue=0.10825810476960021)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.ttest_ind(df['novels.txt'], df['novels-415.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kcna.txt : novels-415.txt\n",
      "Ttest_indResult(statistic=-1.9925895746961764, pvalue=0.04633354914603183)\n",
      "kcna.txt : novels.txt\n",
      "Ttest_indResult(statistic=-0.19871218920210995, pvalue=0.8424919290229935)\n",
      "kcna.txt : pulmyol.txt\n",
      "Ttest_indResult(statistic=-2.285899975225016, pvalue=0.022280935649715887)\n",
      "novels-415.txt : novels.txt\n",
      "Ttest_indResult(statistic=1.6062157018139056, pvalue=0.10825810476960021)\n",
      "novels-415.txt : pulmyol.txt\n",
      "Ttest_indResult(statistic=0.02962811881368405, pvalue=0.9763642309487608)\n",
      "novels.txt : pulmyol.txt\n",
      "Ttest_indResult(statistic=-1.7660209785665917, pvalue=0.07742284297112875)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "for a, b in list(combinations(df.columns, 2)):\n",
    "    print(f'{a} : {b}')\n",
    "    print(stats.ttest_ind(df[a],df[b]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
