{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BERT to quantify the predictability of writing style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer-based models of language such as BERT have been used create state-of-the-art models for a wide range of NLP tasks over the past few years. \n",
    "BERT's next-sentence prediction's capability have recently been used to <a href='https://tedunderwood.com/2020/07/05/how-predictable-is-fiction/'>assess the predictability of fiction.</a> \n",
    "This notebook attempts to use another task that BERT can be trained on, masked language modeling, to assess the predictability of style within a single sentence.\n",
    "\n",
    "In lay language, masked language modeling can be described as a fill-in-the-blanks task. A model is given a sentence, each token in the sentence is hidden and the model made to predict it using the surrounding context words. The idea is that we can use the probabilities generated by such a model to assess how predictable the style of a sentence is. For instance, in the following English language sentence:\n",
    "\n",
    "    His hair as gold as the sun , his eyes blue like the [MASK].\n",
    "\n",
    "BERT (English) can predict `sky` with a 27.1% probability. But in the this sentence:\n",
    "\n",
    "    `The [MASK] above the port was the color of television, tuned to a dead channel`\n",
    "\n",
    "the probability of `sky` falls much lower, with BERT instead giving tokens such as `screen`, `window` or `panel` the highest probabilities - since the comparison to television makes the presence of the word less predictable. In short, BERT is better at predicting boilerplate than original writing. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "I would like to extend this beyond the scope of a single word and onto the scale of a complete sentence, i.e. evaluating a sentence's predictability. This approach makes sense because the way BERT computes probability would reflect a couple of things typically associated with literary originality: \n",
    "- the \"preciosity\" of a word (given two synonyms, the rarer one will receive a lower probability)\n",
    "- the unexpectedness of comparison and literary or poetic language (we might say, in structuralist terms, that BERT's probabilities are computed following paradigmatic (predicting a word over others) and syntagmatic (based on its context) axes, whose order are subverted by the \"poetic function\" of language)\n",
    "\n",
    "This predictability score could then be used as a metric for literary creativity. Being able to quantify such a value would be interesting for literary history and comparative literature, for instance if we were to compare it against signs of literary recognition (literary prizes, publication in prestigious or non-prestigious publishing houses...), enabling us to evaluate how much a certain literary culture values conformity over creativity (or vice-versa) at a certain point in time.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "The insight that a language model can be used to assert how \"common\" the style of sentence is not entirely new. The scoring of sentences by language models, known as <a href='https://en.wikipedia.org/wiki/Perplexity#:~:text=of%20size%20N).-,Perplexity%20per%20word,over%20entire%20sentences%20or%20texts.'>perplexity</a> has been used in tasks such as automatic translation to rate which of the outputs of a model might be the most well-formed sentence in a particular target language. The main differences with our case are that:\n",
    "1. Traditional language models are sequential, working from left to right. They do not use the whole sentence as context to predict a single word. Some models combine left-to-right models with right-to-left models, but the process is still different from BERT since the probability is computed from the knowledge of what comes before only and what comes after only, not on the entire context.\n",
    "2. Working with literary texts, we can assume that the sentences we will feed into the model will be generally gramatically correct (or intentionally incorrect). This allows us to be more selective in the categories of word we want to evaluate, skipping pronouns or particles (*still requires further investigation*).\n",
    "\n",
    "Regarding point 1, BERT gives us an advantage over sequential language models. Because it is bi-directional, it allows us to consider the context on both sides of a word, which is closer to how a human reader would assert the unexpectedness of a single word within a sentence. \n",
    "\n",
    "<a href=' https://arxiv.org/pdf/1906.00363.pdf'>Wang et al (2019)</a> averaged the probabilities of the tokens in a sentence ($\\prod_{i=1}^{n}p(w_{i}|w_{1},...,w_{i-1},w_{i+1},...,w_{n}))^{-1/n} $) to predict whether a sentence is non-sensical or not - similar to how the perplexity score is used by sequential language models. \n",
    "\n",
    "<a href='https://assets.amazon.science/cc/54/980cb7d74f93849b49b9d5c42466/masked-language-model-scoring.pdf'>Salazar et al (2020)</a> develop a measure of \"pseudo-perplexity\" to rank sentences with BERT by used log probabilities. This pseudo-perplexity is defined as: $exp(-1/n\\sum_{i=1}^{n}log(p(w_{i}|w_{1},...,w_{i-1},w_{i+1},...,w_{n})))) $. This is the measure we'll rely on. \n",
    "\n",
    "Point 2 is tied to language specific issues, adressed in the \"Language specifics\" section below.\n",
    "\n",
    "### Issues with the metric\n",
    "\n",
    "Perplexity score is traditionally used to rank different versions of the *same sentence* when generating text with a language model. Because the variation between such sentences is limited, it seems that the behavior of the perplexity score across widely different sentences (as we are doing here) is still unexplored. \n",
    "Differences in perplexity scores are minimal. Probabilities for every word tend to be low, but the absolute value hardly matters, the differential from the next word's probability is important. The difference in the mean values of the sentences of our corpus will likewise be tiny, statistical significance may be achieved because of large sample size, but whether that indeed represents an actual effect is less certain.\n",
    "\n",
    "### Language specifics\n",
    "\n",
    "Working with Korean and with literary texts, the above formula seems to present some limitations. For instance, Korean can mark the object of a verb with a specific particle (를/을). Predicting this particle being present between a noun and a verb is not hard (tokenizers such as BERT's separate it from the noun to which it would be attached). Therefore the token would be assigned a high probability. However, case particles can and are often omitted depending on context and individual preferences. Including it in the scoring of a sentence might therefore introduce bias, ranking writers who use it extensively as less creative than writers who use it more sparingly. On the other hand, as noted in Point 2 above, we are not interested in evaluating the grammatical correctness of a sentence, and therefore including case particles bring little additional information to our metric. The same is true of punctuation, pronouns, prepositions... We therefore opt to restrict the model to predicting masked nouns, adjectives and verbs (all tokens are still nonetheless used as context).\n",
    "\n",
    "### Technical specifics\n",
    "\n",
    "This approach requires us to be able to control the tokenization process because we want to be able to select the words which we will mask for prediction. Because most implementations of BERT uses a type of tokenizer that works splitting more complex words into smaller words to retain a small vocabulary size. This choice of tokenizing method is a powerful way to deal with out-of-vocabulary words (they will be split into smaller, in-vocabulary pieces). \n",
    "\n",
    "To address this issue, I've pre-tokenized the training data used during fine-tuning. I then train a new tokenizer with a large dictionary size and use its vocabulary to update the tokenizer's vocabulary of the base BERT model used for fine-tuning. (see <a href='https://github.com/digitalprk/sih_notebooks/blob/master/run_language_modeling.py'>here</a>). (Note that this extra step would not be needed if we did not want to exclude certain grammatical categories: we could simply use the mean of the probabilities of the differents parts of a word that was split as the probability of that word).\n",
    "\n",
    "The base model used was <a href='https://github.com/SKTBrain/KoBERT'>KoBERT</a>, a BERT model trained by the SK Telecom team on South Korean language data. The model was fine-tuned on a small (1.6Gb) corpus of North Korean language data comprising novels, literary journals, newspapers, non-fiction books and the complete works of Kim Il-Sung and Kim Jong-Il.\n",
    "\n",
    "### Data\n",
    "\n",
    "30000 Sentences were extracted from four types of sources:\n",
    "1. The Korean Central News Agency (the North Korean state's press agency)\n",
    "2. Novels by prestigious writers (recognized for their literary excellence with a state sanctioned distinction)\n",
    "3. Novels by \"regular\" writers\n",
    "4. Canonical novels (fictional accounts of the lives of Kim Il-Sung and Kim Jong-Il held to be of the highest literary quality). \n",
    "5. Collections of poetry\n",
    "\n",
    "None of the novels or press releases used were present in the corpus used to fine-tune the model. However, the corpus did contain similar content (literary sources and press releases for different years). All content used came from the years 1967 - 2018.\n",
    "\n",
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27133b2ad48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df.boxplot(figsize = (15, 10), showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Canonical Novels.txt</th>\n",
       "      <th>Central News Agency.txt</th>\n",
       "      <th>Poetry.txt</th>\n",
       "      <th>Prestigious Novels.txt</th>\n",
       "      <th>Regular Novels.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>3.717125e-04</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>7.810524e-04</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.595703e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>9.288890e-05</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>1.920330e-04</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>3.979100e-04</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.008501</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>3.953910e-02</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.004886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Canonical Novels.txt  Central News Agency.txt    Poetry.txt  \\\n",
       "count          10000.000000             10000.000000  1.000000e+04   \n",
       "mean               0.000251                 0.000243  3.717125e-04   \n",
       "std                0.000270                 0.000141  7.810524e-04   \n",
       "min                0.000000                 0.000000  4.595703e-07   \n",
       "25%                0.000120                 0.000149  9.288890e-05   \n",
       "50%                0.000187                 0.000214  1.920330e-04   \n",
       "75%                0.000297                 0.000301  3.979100e-04   \n",
       "max                0.008501                 0.002298  3.953910e-02   \n",
       "\n",
       "       Prestigious Novels.txt  Regular Novels.txt  \n",
       "count            10000.000000        10000.000000  \n",
       "mean                 0.000257            0.000246  \n",
       "std                  0.000307            0.000247  \n",
       "min                  0.000004            0.000003  \n",
       "25%                  0.000116            0.000115  \n",
       "50%                  0.000184            0.000183  \n",
       "75%                  0.000299            0.000288  \n",
       "max                  0.007767            0.004886  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonical Novels.txt : Central News Agency.txt\n",
      "Ttest_indResult(statistic=2.552955486164272, pvalue=0.010688673312532326)\n",
      "Canonical Novels.txt : Poetry.txt\n",
      "Ttest_indResult(statistic=-14.648423341306692, pvalue=2.4547739726797334e-48)\n",
      "Canonical Novels.txt : Prestigious Novels.txt\n",
      "Ttest_indResult(statistic=-1.4728912652748583, pvalue=0.14079609596087897)\n",
      "Canonical Novels.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=1.3942278524406801, pvalue=0.16326429911179666)\n",
      "Central News Agency.txt : Poetry.txt\n",
      "Ttest_indResult(statistic=-16.231165951078893, pvalue=7.223306925742566e-59)\n",
      "Central News Agency.txt : Prestigious Novels.txt\n",
      "Ttest_indResult(statistic=-4.08177938362255, pvalue=4.486578683061665e-05)\n",
      "Central News Agency.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=-0.9394757646506924, pvalue=0.34749787648814956)\n",
      "Poetry.txt : Prestigious Novels.txt\n",
      "Ttest_indResult(statistic=13.705254034128503, pvalue=1.4707000490328944e-42)\n",
      "Poetry.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=15.39951471105084, pvalue=3.3320854522790646e-53)\n",
      "Prestigious Novels.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=2.821911884969821, pvalue=0.004778536989939926)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "for a, b in list(combinations(df.columns, 2)):\n",
    "    print(f'{a} : {b}')\n",
    "    print(stats.ttest_ind(df[a],df[b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "- The method seems to be at least working for discriminating between discursive genres (press writing, fiction, poetry)\n",
    "- Poetry might be expected to be the genre with the most creative writing, however the higher predictability of contemporary North Korean poetry is not really surprising for anyone unfortunate enough to be familiar with it.\n",
    "- The method shows little significant difference between subgroups of fiction writing. This may be because there's none and all rely, on average, on the same amount of boilerplate. Comparisons between individual writers might be more meaningful. Other possibilities: issues with the fine-tuned model, wrong assumption that the method can be used indiscriminately on any sentence of a text (need to filter at least dialogue, or select for metaphoric sentences with metaphor detection, wrong assumption that the method actually works as intended...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0930 12:14:43.295866 14160 configuration_utils.py:262] loading configuration file ../jobert\\config.json\n",
      "I0930 12:14:43.297861 14160 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 20839\n",
      "}\n",
      "\n",
      "I0930 12:14:43.298859 14160 tokenization_utils_base.py:1167] Model name '../jobert' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming '../jobert' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0930 12:14:43.299856 14160 tokenization_utils_base.py:1197] Didn't find file ../jobert\\added_tokens.json. We won't load it.\n",
      "I0930 12:14:43.300853 14160 tokenization_utils_base.py:1197] Didn't find file ../jobert\\tokenizer.json. We won't load it.\n",
      "I0930 12:14:43.301850 14160 tokenization_utils_base.py:1252] loading file ../jobert\\vocab.txt\n",
      "I0930 12:14:43.302848 14160 tokenization_utils_base.py:1252] loading file None\n",
      "I0930 12:14:43.303845 14160 tokenization_utils_base.py:1252] loading file ../jobert\\special_tokens_map.json\n",
      "I0930 12:14:43.304842 14160 tokenization_utils_base.py:1252] loading file ../jobert\\tokenizer_config.json\n",
      "I0930 12:14:43.304842 14160 tokenization_utils_base.py:1252] loading file None\n",
      "I0930 12:14:43.621997 14160 configuration_utils.py:262] loading configuration file ../jobert\\config.json\n",
      "I0930 12:14:43.622993 14160 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 20839\n",
      "}\n",
      "\n",
      "I0930 12:14:43.624989 14160 modeling_utils.py:665] loading weights file ../jobert\\pytorch_model.bin\n",
      "W0930 12:14:49.608036 14160 modeling_utils.py:757] Some weights of the model checkpoint at ../jobert were not used when initializing BertForMaskedLM: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "I0930 12:14:49.609032 14160 modeling_utils.py:774] All the weights of BertForMaskedLM were initialized from the model checkpoint at ../jobert.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../jobert\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"../jobert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_word_proba(sequence, word):\n",
    "    global model, tokenizer\n",
    "    input_ids = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "    mask_token_index = torch.where(input_ids == tokenizer.mask_token_id)[1]\n",
    "    token_logits = model(input_ids)[0]\n",
    "    mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "    mask_token_logits = torch.softmax(mask_token_logits, dim=1)\n",
    "    sought_after_token = word\n",
    "    sought_after_token_id = tokenizer.encode(sought_after_token, add_special_tokens=False, add_prefix_space=True)[0]\n",
    "    token_score = mask_token_logits[:, sought_after_token_id]\n",
    "    return token_score.detach().numpy()[0]\n",
    "\n",
    "#def compute_differential_word_proba(sequence, word):\n",
    "    \n",
    "\n",
    "def compute_word_by_word_proba(sequence):\n",
    "    global tokenizer\n",
    "    global komoran\n",
    "    pos_filter = ['VV', 'VA', 'NNG', 'NNP', 'MAG', 'NA', 'SN', 'NR', 'XR'] # we only want to predict verbs, nouns and adjectives\n",
    "    word_dict = {}\n",
    "    tokenized_sequence = komoran.pos(sequence)\n",
    "    sequence = ' '.join([token for token, pos in tokenized_sequence])\n",
    "    for token, pos in tokenized_sequence:\n",
    "        #print(token, pos)\n",
    "        if pos in pos_filter:\n",
    "            masked_sequence = sequence.replace(token, tokenizer.mask_token)\n",
    "            word_dict[token] = compute_word_proba(masked_sequence, token)\n",
    "    return word_dict\n",
    "\n",
    "def geometric_mean(series):\n",
    "    return np.array(series, dtype=np.float64).prod()**(1.0/len(series))\n",
    "\n",
    "def compute_sentence_score(sentence):\n",
    "    return geometric_mean(list(compute_word_by_word_proba(sentence).values()))\n",
    "\n",
    "def compute_sentence_log_likelihood(sentence):\n",
    "    return 1/abs(np.mean([np.log(p) for p in list(compute_word_by_word_proba(sentence).values())]))\n",
    "\n",
    "def compute_sentence_pseudo_perplexity(sentence):\n",
    "    return np.exp(-1/(np.mean([np.log(p) for p in list(compute_word_by_word_proba(sentence).values())])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = '위대한 김일성장군님의 가르치심을 애타게 기다리는 동지들의 념원을 안고 나는 지금 평양으로 가고있소'\n",
    "seq = '위대한 김일성장군님이 제일이다'\n",
    "#seq = \"우리는 어떻게 하나 질좋은 물품을 빨리 자체로 만들어내야 합니다.\"\n",
    "sequence = ' '.join(komoran.morphs(seq))\n",
    "sequence = sequence.replace('김일성', tokenizer.mask_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'위대 하 ㄴ [MASK] 장군 님 이 제일 이 다'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6990, -2.4595, -5.1052,  ..., -1.8082, -2.5336, -3.1876],\n",
      "         [-2.8790, -8.3524, -6.5171,  ..., -4.2770, -3.4975, -4.6486],\n",
      "         [-1.7106, -1.1580, -2.4750,  ..., -0.9362, -2.5466, -5.3267],\n",
      "         ...,\n",
      "         [ 2.7549, -2.1428, -2.7325,  ...,  1.4068,  2.0715, -0.2986],\n",
      "         [ 0.5163, -2.4722, -4.0244,  ..., -3.3173, -0.9281, -1.3267],\n",
      "         [-0.6990, -2.4595, -5.1052,  ..., -1.8082, -2.5336, -3.1876]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['김정일']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input_ids == tokenizer.mask_token_id)[1]\n",
    "token_logits = fill_mask.model(input_ids)[0]\n",
    "print(token_logits)\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "predicted_index = torch.argmax(token_logits[0, mask_token_index]).item()\n",
    "tokenizer.convert_ids_to_tokens([predicted_index])\n",
    "#mask_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0930 12:12:09.467043 14160 configuration_utils.py:262] loading configuration file ../jobert\\config.json\n",
      "I0930 12:12:09.469037 14160 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 20839\n",
      "}\n",
      "\n",
      "I0930 12:12:09.469037 14160 tokenization_utils_base.py:1167] Model name '../jobert' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming '../jobert' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0930 12:12:09.471032 14160 tokenization_utils_base.py:1197] Didn't find file ../jobert\\added_tokens.json. We won't load it.\n",
      "I0930 12:12:09.472029 14160 tokenization_utils_base.py:1197] Didn't find file ../jobert\\tokenizer.json. We won't load it.\n",
      "I0930 12:12:09.473026 14160 tokenization_utils_base.py:1252] loading file ../jobert\\vocab.txt\n",
      "I0930 12:12:09.474024 14160 tokenization_utils_base.py:1252] loading file None\n",
      "I0930 12:12:09.475021 14160 tokenization_utils_base.py:1252] loading file ../jobert\\special_tokens_map.json\n",
      "I0930 12:12:09.475021 14160 tokenization_utils_base.py:1252] loading file ../jobert\\tokenizer_config.json\n",
      "I0930 12:12:09.476019 14160 tokenization_utils_base.py:1252] loading file None\n",
      "I0930 12:12:09.692441 14160 modelcard.py:177] Model card: {\n",
      "  \"caveats_and_recommendations\": {},\n",
      "  \"ethical_considerations\": {},\n",
      "  \"evaluation_data\": {},\n",
      "  \"factors\": {},\n",
      "  \"intended_use\": {},\n",
      "  \"metrics\": {},\n",
      "  \"model_details\": {},\n",
      "  \"quantitative_analyses\": {},\n",
      "  \"training_data\": {}\n",
      "}\n",
      "\n",
      "I0930 12:12:09.693439 14160 configuration_utils.py:262] loading configuration file ../jobert\\config.json\n",
      "I0930 12:12:09.694436 14160 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 20839\n",
      "}\n",
      "\n",
      "I0930 12:12:09.695433 14160 modeling_utils.py:665] loading weights file ../jobert\\pytorch_model.bin\n",
      "W0930 12:12:18.949757 14160 modeling_utils.py:757] Some weights of the model checkpoint at ../jobert were not used when initializing BertForMaskedLM: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "I0930 12:12:18.954743 14160 modeling_utils.py:774] All the weights of BertForMaskedLM were initialized from the model checkpoint at ../jobert.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"../jobert\",\n",
    "    tokenizer=\"../jobert\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '[CLS] 위대 하 ㄴ 김정일 장군 님 의 가르치 시 ㅁ 이 다. [SEP]',\n",
       "  'score': 0.7124444842338562,\n",
       "  'token': 14743,\n",
       "  'token_str': '김정일'},\n",
       " {'sequence': '[CLS] 위대 하 ㄴ 김일성 장군 님 의 가르치 시 ㅁ 이 다. [SEP]',\n",
       "  'score': 0.23677174746990204,\n",
       "  'token': 14754,\n",
       "  'token_str': '김일성'},\n",
       " {'sequence': '[CLS] 위대 하 ㄴ 우리 장군 님 의 가르치 시 ㅁ 이 다. [SEP]',\n",
       "  'score': 0.01945415697991848,\n",
       "  'token': 7007,\n",
       "  'token_str': '우리'},\n",
       " {'sequence': '[CLS] 위대 하 ㄴ 어버이 장군 님 의 가르치 시 ㅁ 이 다. [SEP]',\n",
       "  'score': 0.012761121615767479,\n",
       "  'token': 14882,\n",
       "  'token_str': '어버이'},\n",
       " {'sequence': '[CLS] 위대 하 ㄴ 김정은 장군 님 의 가르치 시 ㅁ 이 다. [SEP]',\n",
       "  'score': 0.0038153172936290503,\n",
       "  'token': 14814,\n",
       "  'token_str': '김정은'}]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask(' '.join(komoran.morphs('위대한 MASK 장군님의 가르치심이다.')).replace('MASK', '[MASK]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7782, 7096, 8557, 7088, 7095])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ensure_tensor_on_device(**inputs):\n",
    "    \"\"\"\n",
    "    Ensure PyTorch tensors are on the specified device.\n",
    "    :param inputs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return {name: tensor.to(torch.device(\"cpu\")) for name, tensor in inputs.items()}\n",
    "\n",
    "sequence = '위대 하 ㄴ [MASK] 장군 님 의 가르치 시 ㅁ 을 애타 게 기다리 는 동지 들 의 념원을 안고 나 는 지금 평양 으로 가 고 있 소 .'\n",
    "inputs = tokenizer.batch_encode_plus([sequence], add_special_tokens=True, return_tensors=\"pt\", pad_to_max_length=True)\n",
    "input_ids = inputs[\"input_ids\"][0]\n",
    "with torch.no_grad():\n",
    "    inputs = ensure_tensor_on_device(**inputs)\n",
    "    outputs = model(**inputs)[0].cpu()\n",
    "    batch_size = outputs.size(0)\n",
    "    for i in range(batch_size):\n",
    "        masked_index = (input_ids == tokenizer.mask_token_id).nonzero().item()\n",
    "        logits = outputs[i, masked_index, :]\n",
    "        probs = logits.softmax(dim=0)\n",
    "        values, predictions = probs.topk(5)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -2.7284, -12.8770, -12.8212,  ...,  -5.7011,  -6.1706,  -6.0741],\n",
       "         [ -2.7284, -12.8770, -12.8212,  ...,  -5.7011,  -6.1706,  -6.0741],\n",
       "         [ -2.7284, -12.8770, -12.8212,  ...,  -5.7011,  -6.1706,  -6.0741],\n",
       "         ...,\n",
       "         [ -2.7284, -12.8770, -12.8212,  ...,  -5.7011,  -6.1706,  -6.0741],\n",
       "         [ -2.7284, -12.8770, -12.8212,  ...,  -5.7011,  -6.1706,  -6.0741],\n",
       "         [ -2.7284, -12.8770, -12.8212,  ...,  -5.7011,  -6.1706,  -6.0741]]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.batch_encode_plus(\n",
    "    inputs, add_special_tokens=True, return_tensors=\"pt\", pad_to_max_length=pad_to_max_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'위대': 0.996847, '김일성': 0.34007233, '장군': 0.33053988, '제일': 0.00081309915}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_word_by_word_proba(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'위대': 0.996847, '김일성': 0.34007233, '장군': 0.33053988, '제일': 0.00081309915}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_word_by_word_proba(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['하']\n",
      "['이']\n",
      "['ㄴ']\n",
      "['을']\n",
      "['의']\n",
      "['는']\n",
      "['다']\n",
      "['에']\n",
      "['들']\n",
      "['은']\n"
     ]
    }
   ],
   "source": [
    "for index in torch.topk(mask_token_logits, 10).indices.tolist()[0]:\n",
    "    print(tokenizer.convert_ids_to_tokens([index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7782, 7096, 54, 7088, 8557, 7095, 5760, 5782, 6896, 5931]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(mask_token_logits, 10).indices.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.8321314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('김정일', 'NNP'),\n",
       " ('동지', 'NNP'),\n",
       " ('께서', 'JKS'),\n",
       " ('는', 'JX'),\n",
       " ('전시', 'NNG'),\n",
       " ('공로', 'NNG'),\n",
       " ('자인', 'NNP'),\n",
       " ('그', 'NP'),\n",
       " ('를', 'JKO'),\n",
       " ('인민군대', 'NNG'),\n",
       " ('의', 'JKG'),\n",
       " ('지휘', 'NNP'),\n",
       " ('성원', 'NNP'),\n",
       " ('으로', 'JKB'),\n",
       " (',', 'SP'),\n",
       " ('조선인민군', 'NNP'),\n",
       " ('장령', 'NNG'),\n",
       " ('으로', 'JKB'),\n",
       " ('내세우', 'VV'),\n",
       " ('어', 'EC'),\n",
       " ('주시', 'NNG'),\n",
       " ('이', 'VCP'),\n",
       " ('었', 'EP'),\n",
       " ('으며', 'EC'),\n",
       " ('전국', 'NNG'),\n",
       " ('로', 'JKB'),\n",
       " ('병', 'NNG'),\n",
       " ('대회', 'NNG'),\n",
       " ('를', 'JKO'),\n",
       " ('비롯', 'XR'),\n",
       " ('하', 'XSA'),\n",
       " ('ㄴ', 'ETM'),\n",
       " ('국가', 'NNG'),\n",
       " ('행사', 'NNG'),\n",
       " ('에', 'JKB'),\n",
       " ('부르', 'VV'),\n",
       " ('어', 'EC'),\n",
       " ('주', 'VX'),\n",
       " ('시', 'EP'),\n",
       " ('고', 'EC'),\n",
       " ('크나크', 'VA'),\n",
       " ('ㄴ', 'ETM'),\n",
       " ('사랑', 'NNG'),\n",
       " ('과', 'JC'),\n",
       " ('은정', 'NNP'),\n",
       " ('을', 'JKO'),\n",
       " ('베풀', 'VV'),\n",
       " ('어', 'EC'),\n",
       " ('주시', 'NNG'),\n",
       " ('이', 'VCP'),\n",
       " ('었', 'EP'),\n",
       " ('다', 'EF'),\n",
       " ('.', 'SF')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = '어린이들이 김대중대통령과 부인에게 꽃다발을 드리였다.'\n",
    "seq = '김정일동지께서는 전시공로자인 그를 인민군대의 지휘성원으로,조선인민군 장령으로 내세워 주시였으며 전국로병대회를 비롯한 국가행사에 불러 주시고 크나큰 사랑과 은정을 베풀어 주시였다.'\n",
    "#seq = '오늘 일본은 위험한 침략세력으로 등장하고 있다.'\n",
    "print(compute_sentence_log_likelihood(seq))\n",
    "komoran.pos(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0991429414537783\n",
      "1.1001011621288694\n",
      "1.0977751200406303\n"
     ]
    }
   ],
   "source": [
    "seq = '젊은이들은 조심히 김진수의 낯빛을 살피며 한숨을 삼켰다.'\n",
    "print(compute_sentence_pseudo_perplexity(seq))\n",
    "seq2 = '젊은이들은 조심히 김진수의 낯빛을 살피며 음식을 삼켰다.'\n",
    "print(compute_sentence_pseudo_perplexity(seq2))\n",
    "seq3 = '젊은이들은 조심히 김진수의 낯빛을 살피며 도서관을 삼켰다.'\n",
    "print(compute_sentence_pseudo_perplexity(seq3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'젊은이들': 1.877197e-05,\n",
       " '은': 0.013749413,\n",
       " '조': 0.00045248694,\n",
       " '심히': 2.7240125e-05,\n",
       " '김진수': 2.714073e-06,\n",
       " '의': 0.024211552,\n",
       " '낯빛': 4.5080662e-05,\n",
       " '을': 0.025879815,\n",
       " '살피': 1.7681034e-05,\n",
       " '며': 0.003192315,\n",
       " '음식': 5.301463e-05,\n",
       " '삼키': 1.4393001e-05,\n",
       " '었': 0.0097162565,\n",
       " '다': 0.018258544,\n",
       " '.': 0.028696485}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_word_by_word_proba(seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonical Novels.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                  | 0/50 [00:00<?, ?it/s]\n",
      "\n",
      "  2%|███▍                                                                                                                                                                      | 1/50 [00:01<00:48,  1.00it/s]\n",
      "\n",
      "  4%|██████▊                                                                                                                                                                   | 2/50 [00:01<00:38,  1.24it/s]\n",
      "\n",
      "  6%|██████████▏                                                                                                                                                               | 3/50 [00:01<00:31,  1.49it/s]\n",
      "\n",
      "  8%|█████████████▌                                                                                                                                                            | 4/50 [00:02<00:34,  1.34it/s]\n",
      "\n",
      " 10%|█████████████████                                                                                                                                                         | 5/50 [00:02<00:26,  1.68it/s]\n",
      "\n",
      " 12%|████████████████████▍                                                                                                                                                     | 6/50 [00:05<00:47,  1.09s/it]\n",
      "\n",
      " 14%|███████████████████████▊                                                                                                                                                  | 7/50 [00:05<00:38,  1.11it/s]\n",
      "\n",
      " 16%|███████████████████████████▏                                                                                                                                              | 8/50 [00:05<00:30,  1.37it/s]\n",
      "\n",
      " 18%|██████████████████████████████▌                                                                                                                                           | 9/50 [00:12<01:39,  2.42s/it]\n",
      "\n",
      " 20%|█████████████████████████████████▊                                                                                                                                       | 10/50 [00:15<01:43,  2.58s/it]\n",
      "\n",
      " 22%|█████████████████████████████████████▏                                                                                                                                   | 11/50 [00:16<01:21,  2.08s/it]\n",
      "\n",
      " 24%|████████████████████████████████████████▌                                                                                                                                | 12/50 [00:16<01:02,  1.63s/it]\n",
      "\n",
      " 26%|███████████████████████████████████████████▉                                                                                                                             | 13/50 [00:17<00:48,  1.32s/it]\n",
      "\n",
      " 28%|███████████████████████████████████████████████▎                                                                                                                         | 14/50 [00:18<00:41,  1.14s/it]\n",
      "\n",
      " 30%|██████████████████████████████████████████████████▋                                                                                                                      | 15/50 [00:18<00:31,  1.11it/s]\n",
      "\n",
      " 32%|██████████████████████████████████████████████████████                                                                                                                   | 16/50 [00:20<00:41,  1.23s/it]\n",
      "\n",
      " 34%|█████████████████████████████████████████████████████████▍                                                                                                               | 17/50 [00:20<00:32,  1.03it/s]\n",
      "\n",
      " 36%|████████████████████████████████████████████████████████████▊                                                                                                            | 18/50 [00:21<00:27,  1.16it/s]\n",
      "\n",
      " 38%|████████████████████████████████████████████████████████████████▏                                                                                                        | 19/50 [00:21<00:21,  1.43it/s]\n",
      "\n",
      " 40%|███████████████████████████████████████████████████████████████████▌                                                                                                     | 20/50 [00:24<00:35,  1.20s/it]\n",
      "\n",
      " 42%|██████████████████████████████████████████████████████████████████████▉                                                                                                  | 21/50 [00:24<00:28,  1.03it/s]\n",
      "\n",
      " 44%|██████████████████████████████████████████████████████████████████████████▎                                                                                              | 22/50 [00:25<00:24,  1.13it/s]\n",
      "\n",
      " 46%|█████████████████████████████████████████████████████████████████████████████▋                                                                                           | 23/50 [00:25<00:22,  1.22it/s]\n",
      "\n",
      " 48%|█████████████████████████████████████████████████████████████████████████████████                                                                                        | 24/50 [00:26<00:20,  1.25it/s]\n",
      "\n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 25/50 [00:27<00:19,  1.30it/s]\n",
      "\n",
      " 52%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 26/50 [00:28<00:18,  1.28it/s]\n",
      "\n",
      " 54%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                             | 27/50 [00:28<00:15,  1.44it/s]\n",
      "\n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                                          | 28/50 [00:30<00:26,  1.21s/it]\n",
      "\n",
      " 58%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 29/50 [00:31<00:20,  1.03it/s]\n",
      "\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                   | 30/50 [00:31<00:17,  1.17it/s]\n",
      "\n",
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                | 31/50 [00:32<00:14,  1.35it/s]\n",
      "\n",
      " 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                            | 32/50 [00:32<00:11,  1.60it/s]\n",
      "\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                         | 33/50 [00:33<00:11,  1.47it/s]\n",
      "\n",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 34/50 [00:34<00:09,  1.63it/s]\n",
      "\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 35/50 [00:42<00:43,  2.92s/it]\n",
      "\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 36/50 [00:43<00:32,  2.31s/it]\n",
      "\n",
      " 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 37/50 [00:43<00:21,  1.68s/it]\n",
      "\n",
      " 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 38/50 [00:43<00:15,  1.28s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 39/50 [00:44<00:12,  1.12s/it]\n",
      "\n",
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                 | 40/50 [00:45<00:09,  1.02it/s]\n",
      "\n",
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                              | 41/50 [00:45<00:07,  1.18it/s]\n",
      "\n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                           | 42/50 [00:46<00:06,  1.17it/s]\n",
      "\n",
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                       | 43/50 [00:46<00:04,  1.44it/s]\n",
      "\n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 44/50 [00:47<00:03,  1.62it/s]\n",
      "\n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 45/50 [00:48<00:03,  1.36it/s]\n",
      "\n",
      " 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 46/50 [00:49<00:03,  1.33it/s]\n",
      "\n",
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 47/50 [00:49<00:01,  1.51it/s]\n",
      "\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 48/50 [00:50<00:01,  1.72it/s]\n",
      "\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 49/50 [00:52<00:01,  1.14s/it]\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:52<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central News Agency.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                  | 0/50 [00:00<?, ?it/s]\n",
      "\n",
      "  2%|███▍                                                                                                                                                                      | 1/50 [00:01<01:04,  1.31s/it]\n",
      "\n",
      "  4%|██████▊                                                                                                                                                                   | 2/50 [00:04<01:23,  1.75s/it]\n",
      "\n",
      "  6%|██████████▏                                                                                                                                                               | 3/50 [00:04<01:08,  1.45s/it]\n",
      "\n",
      "  8%|█████████████▌                                                                                                                                                            | 4/50 [00:05<01:00,  1.31s/it]\n",
      "\n",
      " 10%|█████████████████                                                                                                                                                         | 5/50 [00:07<01:07,  1.50s/it]\n",
      "\n",
      " 12%|████████████████████▍                                                                                                                                                     | 6/50 [00:09<01:03,  1.45s/it]\n",
      "\n",
      " 14%|███████████████████████▊                                                                                                                                                  | 7/50 [00:09<00:47,  1.11s/it]\n",
      "\n",
      " 16%|███████████████████████████▏                                                                                                                                              | 8/50 [00:10<00:41,  1.01it/s]\n",
      "\n",
      " 18%|██████████████████████████████▌                                                                                                                                           | 9/50 [00:11<00:39,  1.04it/s]\n",
      "\n",
      " 20%|█████████████████████████████████▊                                                                                                                                       | 10/50 [00:13<00:56,  1.41s/it]\n",
      "\n",
      " 22%|█████████████████████████████████████▏                                                                                                                                   | 11/50 [00:15<01:01,  1.56s/it]\n",
      "\n",
      " 24%|████████████████████████████████████████▌                                                                                                                                | 12/50 [00:15<00:47,  1.24s/it]\n",
      "\n",
      " 26%|███████████████████████████████████████████▉                                                                                                                             | 13/50 [00:16<00:44,  1.20s/it]\n",
      "\n",
      " 28%|███████████████████████████████████████████████▎                                                                                                                         | 14/50 [00:17<00:36,  1.02s/it]\n",
      "\n",
      " 30%|██████████████████████████████████████████████████▋                                                                                                                      | 15/50 [00:18<00:31,  1.09it/s]\n",
      "\n",
      " 32%|██████████████████████████████████████████████████████                                                                                                                   | 16/50 [00:18<00:25,  1.33it/s]\n",
      "\n",
      " 34%|█████████████████████████████████████████████████████████▍                                                                                                               | 17/50 [00:20<00:31,  1.04it/s]\n",
      "\n",
      " 36%|████████████████████████████████████████████████████████████▊                                                                                                            | 18/50 [00:23<00:50,  1.57s/it]\n",
      "\n",
      " 38%|████████████████████████████████████████████████████████████████▏                                                                                                        | 19/50 [00:24<00:51,  1.65s/it]\n",
      "\n",
      " 40%|███████████████████████████████████████████████████████████████████▌                                                                                                     | 20/50 [00:25<00:37,  1.25s/it]\n",
      "\n",
      " 42%|██████████████████████████████████████████████████████████████████████▉                                                                                                  | 21/50 [00:25<00:28,  1.02it/s]\n",
      "\n",
      " 44%|██████████████████████████████████████████████████████████████████████████▎                                                                                              | 22/50 [00:28<00:39,  1.42s/it]\n",
      "\n",
      " 46%|█████████████████████████████████████████████████████████████████████████████▋                                                                                           | 23/50 [00:30<00:50,  1.86s/it]\n",
      "\n",
      " 48%|█████████████████████████████████████████████████████████████████████████████████                                                                                        | 24/50 [00:32<00:43,  1.67s/it]\n",
      "\n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 25/50 [00:33<00:35,  1.44s/it]\n",
      "\n",
      " 52%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 26/50 [00:35<00:43,  1.83s/it]\n",
      "\n",
      " 54%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                             | 27/50 [00:37<00:42,  1.84s/it]\n",
      "\n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                                          | 28/50 [00:38<00:36,  1.66s/it]\n",
      "\n",
      " 58%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 29/50 [00:40<00:32,  1.56s/it]\n",
      "\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                   | 30/50 [00:41<00:27,  1.37s/it]\n",
      "\n",
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                | 31/50 [00:42<00:23,  1.25s/it]\n",
      "\n",
      " 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                            | 32/50 [00:44<00:27,  1.55s/it]\n",
      "\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                         | 33/50 [00:46<00:29,  1.73s/it]\n",
      "\n",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 34/50 [00:47<00:24,  1.56s/it]\n",
      "\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 35/50 [00:48<00:21,  1.43s/it]\n",
      "\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 36/50 [00:49<00:17,  1.24s/it]\n",
      "\n",
      " 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 37/50 [00:49<00:12,  1.05it/s]\n",
      "\n",
      " 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 38/50 [00:54<00:23,  1.96s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 39/50 [00:56<00:21,  1.96s/it]\n",
      "\n",
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                 | 40/50 [00:57<00:17,  1.75s/it]\n",
      "\n",
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                              | 41/50 [01:03<00:27,  3.06s/it]\n",
      "\n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                           | 42/50 [01:05<00:22,  2.86s/it]\n",
      "\n",
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                       | 43/50 [01:06<00:16,  2.29s/it]\n",
      "\n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 44/50 [01:09<00:13,  2.25s/it]\n",
      "\n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 45/50 [01:11<00:12,  2.43s/it]\n",
      "\n",
      " 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 46/50 [01:14<00:10,  2.57s/it]\n",
      "\n",
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 47/50 [01:18<00:08,  2.81s/it]\n",
      "\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 48/50 [01:19<00:04,  2.42s/it]\n",
      "\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 49/50 [01:22<00:02,  2.52s/it]\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:26<00:00,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poetry.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                  | 0/50 [00:00<?, ?it/s]\n",
      "\n",
      "  2%|███▍                                                                                                                                                                      | 1/50 [00:00<00:14,  3.39it/s]\n",
      "\n",
      "  4%|██████▊                                                                                                                                                                   | 2/50 [00:00<00:13,  3.61it/s]\n",
      "\n",
      "  8%|█████████████▌                                                                                                                                                            | 4/50 [00:00<00:10,  4.56it/s]\n",
      "\n",
      " 12%|████████████████████▍                                                                                                                                                     | 6/50 [00:00<00:08,  5.21it/s]\n",
      "\n",
      " 14%|███████████████████████▊                                                                                                                                                  | 7/50 [00:01<00:08,  4.92it/s]\n",
      "\n",
      " 16%|███████████████████████████▏                                                                                                                                              | 8/50 [00:01<00:10,  4.07it/s]\n",
      "\n",
      " 18%|██████████████████████████████▌                                                                                                                                           | 9/50 [00:01<00:09,  4.51it/s]\n",
      "\n",
      " 20%|█████████████████████████████████▊                                                                                                                                       | 10/50 [00:01<00:08,  4.83it/s]\n",
      "\n",
      " 24%|████████████████████████████████████████▌                                                                                                                                | 12/50 [00:02<00:07,  4.82it/s]\n",
      "\n",
      " 28%|███████████████████████████████████████████████▎                                                                                                                         | 14/50 [00:02<00:06,  5.37it/s]\n",
      "\n",
      " 30%|██████████████████████████████████████████████████▋                                                                                                                      | 15/50 [00:02<00:05,  5.90it/s]\n",
      "\n",
      " 32%|██████████████████████████████████████████████████████                                                                                                                   | 16/50 [00:02<00:05,  5.87it/s]\n",
      "\n",
      " 34%|█████████████████████████████████████████████████████████▍                                                                                                               | 17/50 [00:02<00:05,  6.30it/s]\n",
      "\n",
      " 36%|████████████████████████████████████████████████████████████▊                                                                                                            | 18/50 [00:03<00:05,  6.09it/s]\n",
      "\n",
      " 38%|████████████████████████████████████████████████████████████████▏                                                                                                        | 19/50 [00:03<00:05,  5.86it/s]\n",
      "\n",
      " 40%|███████████████████████████████████████████████████████████████████▌                                                                                                     | 20/50 [00:03<00:04,  6.16it/s]\n",
      "\n",
      " 44%|██████████████████████████████████████████████████████████████████████████▎                                                                                              | 22/50 [00:03<00:04,  6.88it/s]\n",
      "\n",
      " 46%|█████████████████████████████████████████████████████████████████████████████▋                                                                                           | 23/50 [00:03<00:03,  7.14it/s]\n",
      "\n",
      " 48%|█████████████████████████████████████████████████████████████████████████████████                                                                                        | 24/50 [00:03<00:03,  7.34it/s]\n",
      "\n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 25/50 [00:04<00:03,  7.33it/s]\n",
      "\n",
      " 52%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 26/50 [00:04<00:03,  6.63it/s]\n",
      "\n",
      " 54%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                             | 27/50 [00:04<00:03,  6.70it/s]\n",
      "\n",
      " 58%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 29/50 [00:04<00:03,  6.58it/s]\n",
      "\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                   | 30/50 [00:04<00:03,  5.62it/s]\n",
      "\n",
      " 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                            | 32/50 [00:05<00:02,  6.28it/s]\n",
      "\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                         | 33/50 [00:05<00:02,  6.54it/s]\n",
      "\n",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 34/50 [00:05<00:03,  5.07it/s]\n",
      "\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 35/50 [00:05<00:03,  4.32it/s]\n",
      "\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 36/50 [00:06<00:02,  4.95it/s]\n",
      "\n",
      " 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 38/50 [00:06<00:02,  5.80it/s]\n",
      "\n",
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 39/50 [00:06<00:01,  6.15it/s]\n",
      "\n",
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                 | 40/50 [00:06<00:01,  5.60it/s]\n",
      "\n",
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                              | 41/50 [00:06<00:01,  5.25it/s]\n",
      "\n",
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                       | 43/50 [00:07<00:01,  5.76it/s]\n",
      "\n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 44/50 [00:07<00:01,  5.63it/s]\n",
      "\n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 45/50 [00:07<00:01,  4.31it/s]\n",
      "\n",
      " 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 46/50 [00:07<00:00,  4.59it/s]\n",
      "\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 48/50 [00:08<00:00,  4.96it/s]\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:08<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prestigious Novels.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                  | 0/50 [00:00<?, ?it/s]\n",
      "\n",
      "  2%|███▍                                                                                                                                                                      | 1/50 [00:00<00:12,  3.96it/s]\n",
      "\n",
      "  4%|██████▊                                                                                                                                                                   | 2/50 [00:00<00:16,  2.87it/s]\n",
      "\n",
      "  6%|██████████▏                                                                                                                                                               | 3/50 [00:01<00:14,  3.19it/s]\n",
      "\n",
      "  8%|█████████████▌                                                                                                                                                            | 4/50 [00:01<00:21,  2.19it/s]\n",
      "\n",
      " 10%|█████████████████                                                                                                                                                         | 5/50 [00:02<00:23,  1.95it/s]\n",
      "\n",
      " 12%|████████████████████▍                                                                                                                                                     | 6/50 [00:03<00:25,  1.73it/s]\n",
      "\n",
      " 14%|███████████████████████▊                                                                                                                                                  | 7/50 [00:03<00:23,  1.84it/s]\n",
      "\n",
      " 16%|███████████████████████████▏                                                                                                                                              | 8/50 [00:05<00:41,  1.00it/s]\n",
      "\n",
      " 18%|██████████████████████████████▌                                                                                                                                           | 9/50 [00:05<00:31,  1.30it/s]\n",
      "\n",
      " 20%|█████████████████████████████████▊                                                                                                                                       | 10/50 [00:06<00:27,  1.48it/s]\n",
      "\n",
      " 22%|█████████████████████████████████████▏                                                                                                                                   | 11/50 [00:07<00:25,  1.55it/s]\n",
      "\n",
      " 24%|████████████████████████████████████████▌                                                                                                                                | 12/50 [00:07<00:23,  1.61it/s]\n",
      "\n",
      " 26%|███████████████████████████████████████████▉                                                                                                                             | 13/50 [00:08<00:22,  1.67it/s]\n",
      "\n",
      " 28%|███████████████████████████████████████████████▎                                                                                                                         | 14/50 [00:09<00:25,  1.39it/s]\n",
      "\n",
      " 30%|██████████████████████████████████████████████████▋                                                                                                                      | 15/50 [00:10<00:29,  1.17it/s]\n",
      "\n",
      " 32%|██████████████████████████████████████████████████████                                                                                                                   | 16/50 [00:11<00:35,  1.05s/it]\n",
      "\n",
      " 34%|█████████████████████████████████████████████████████████▍                                                                                                               | 17/50 [00:12<00:28,  1.17it/s]\n",
      "\n",
      " 36%|████████████████████████████████████████████████████████████▊                                                                                                            | 18/50 [00:16<01:00,  1.89s/it]\n",
      "\n",
      " 38%|████████████████████████████████████████████████████████████████▏                                                                                                        | 19/50 [00:20<01:13,  2.38s/it]\n",
      "\n",
      " 40%|███████████████████████████████████████████████████████████████████▌                                                                                                     | 20/50 [00:20<00:53,  1.77s/it]\n",
      "\n",
      " 42%|██████████████████████████████████████████████████████████████████████▉                                                                                                  | 21/50 [00:21<00:43,  1.50s/it]\n",
      "\n",
      " 44%|██████████████████████████████████████████████████████████████████████████▎                                                                                              | 22/50 [00:21<00:34,  1.24s/it]\n",
      "\n",
      " 46%|█████████████████████████████████████████████████████████████████████████████▋                                                                                           | 23/50 [00:22<00:28,  1.06s/it]\n",
      "\n",
      " 48%|█████████████████████████████████████████████████████████████████████████████████                                                                                        | 24/50 [00:22<00:21,  1.22it/s]\n",
      "\n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 25/50 [00:23<00:18,  1.37it/s]\n",
      "\n",
      " 52%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 26/50 [00:23<00:15,  1.51it/s]\n",
      "\n",
      " 54%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                             | 27/50 [00:24<00:18,  1.28it/s]\n",
      "\n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                                          | 28/50 [00:25<00:15,  1.39it/s]\n",
      "\n",
      " 58%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 29/50 [00:25<00:11,  1.75it/s]\n",
      "\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                   | 30/50 [00:26<00:12,  1.61it/s]\n",
      "\n",
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                | 31/50 [00:26<00:10,  1.78it/s]\n",
      "\n",
      " 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                            | 32/50 [00:27<00:11,  1.56it/s]\n",
      "\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                         | 33/50 [00:28<00:09,  1.75it/s]\n",
      "\n",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 34/50 [00:28<00:08,  1.99it/s]\n",
      "\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 35/50 [00:28<00:07,  2.04it/s]\n",
      "\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 36/50 [00:29<00:06,  2.16it/s]\n",
      "\n",
      " 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 37/50 [00:29<00:05,  2.27it/s]\n",
      "\n",
      " 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 38/50 [00:30<00:05,  2.19it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 39/50 [00:30<00:05,  1.97it/s]\n",
      "\n",
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                 | 40/50 [00:31<00:05,  1.89it/s]\n",
      "\n",
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                              | 41/50 [00:31<00:04,  1.90it/s]\n",
      "\n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                           | 42/50 [00:32<00:04,  1.87it/s]\n",
      "\n",
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                       | 43/50 [00:33<00:04,  1.59it/s]\n",
      "\n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 44/50 [00:35<00:06,  1.02s/it]\n",
      "\n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 45/50 [00:35<00:03,  1.29it/s]\n",
      "\n",
      " 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 46/50 [00:35<00:02,  1.54it/s]\n",
      "\n",
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 47/50 [00:36<00:01,  1.52it/s]\n",
      "\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 48/50 [00:36<00:01,  1.97it/s]\n",
      "\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 49/50 [00:37<00:00,  1.54it/s]\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:37<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Novels.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                  | 0/50 [00:00<?, ?it/s]\n",
      "\n",
      "  2%|███▍                                                                                                                                                                      | 1/50 [00:00<00:23,  2.07it/s]\n",
      "\n",
      "  4%|██████▊                                                                                                                                                                   | 2/50 [00:00<00:20,  2.32it/s]\n",
      "\n",
      "  6%|██████████▏                                                                                                                                                               | 3/50 [00:01<00:20,  2.24it/s]\n",
      "\n",
      "  8%|█████████████▌                                                                                                                                                            | 4/50 [00:01<00:22,  2.01it/s]\n",
      "\n",
      " 10%|█████████████████                                                                                                                                                         | 5/50 [00:02<00:23,  1.90it/s]\n",
      "\n",
      " 12%|████████████████████▍                                                                                                                                                     | 6/50 [00:03<00:24,  1.81it/s]\n",
      "\n",
      " 14%|███████████████████████▊                                                                                                                                                  | 7/50 [00:03<00:19,  2.18it/s]\n",
      "\n",
      " 16%|███████████████████████████▏                                                                                                                                              | 8/50 [00:03<00:17,  2.39it/s]\n",
      "\n",
      " 18%|██████████████████████████████▌                                                                                                                                           | 9/50 [00:03<00:15,  2.65it/s]\n",
      "\n",
      " 20%|█████████████████████████████████▊                                                                                                                                       | 10/50 [00:04<00:16,  2.36it/s]\n",
      "\n",
      " 22%|█████████████████████████████████████▏                                                                                                                                   | 11/50 [00:04<00:17,  2.25it/s]\n",
      "\n",
      " 24%|████████████████████████████████████████▌                                                                                                                                | 12/50 [00:05<00:16,  2.25it/s]\n",
      "\n",
      " 26%|███████████████████████████████████████████▉                                                                                                                             | 13/50 [00:06<00:22,  1.62it/s]\n",
      "\n",
      " 28%|███████████████████████████████████████████████▎                                                                                                                         | 14/50 [00:06<00:17,  2.02it/s]\n",
      "\n",
      " 30%|██████████████████████████████████████████████████▋                                                                                                                      | 15/50 [00:07<00:16,  2.17it/s]\n",
      "\n",
      " 32%|██████████████████████████████████████████████████████                                                                                                                   | 16/50 [00:09<00:34,  1.01s/it]\n",
      "\n",
      " 34%|█████████████████████████████████████████████████████████▍                                                                                                               | 17/50 [00:09<00:29,  1.14it/s]\n",
      "\n",
      " 36%|████████████████████████████████████████████████████████████▊                                                                                                            | 18/50 [00:10<00:25,  1.24it/s]\n",
      "\n",
      " 38%|████████████████████████████████████████████████████████████████▏                                                                                                        | 19/50 [00:11<00:28,  1.10it/s]\n",
      "\n",
      " 40%|███████████████████████████████████████████████████████████████████▌                                                                                                     | 20/50 [00:12<00:23,  1.27it/s]\n",
      "\n",
      " 42%|██████████████████████████████████████████████████████████████████████▉                                                                                                  | 21/50 [00:12<00:21,  1.33it/s]\n",
      "\n",
      " 44%|██████████████████████████████████████████████████████████████████████████▎                                                                                              | 22/50 [00:13<00:19,  1.43it/s]\n",
      "\n",
      " 46%|█████████████████████████████████████████████████████████████████████████████▋                                                                                           | 23/50 [00:13<00:16,  1.65it/s]\n",
      "\n",
      " 48%|█████████████████████████████████████████████████████████████████████████████████                                                                                        | 24/50 [00:14<00:13,  1.90it/s]\n",
      "\n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 25/50 [00:14<00:14,  1.79it/s]\n",
      "\n",
      " 52%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 26/50 [00:15<00:11,  2.13it/s]\n",
      "\n",
      " 54%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                             | 27/50 [00:15<00:12,  1.79it/s]\n",
      "\n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                                          | 28/50 [00:16<00:12,  1.76it/s]\n",
      "\n",
      " 58%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 29/50 [00:17<00:14,  1.49it/s]\n",
      "\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                   | 30/50 [00:18<00:14,  1.41it/s]\n",
      "\n",
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                | 31/50 [00:18<00:14,  1.32it/s]\n",
      "\n",
      " 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                            | 32/50 [00:19<00:10,  1.70it/s]\n",
      "\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                         | 33/50 [00:20<00:13,  1.28it/s]\n",
      "\n",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 34/50 [00:20<00:10,  1.59it/s]\n",
      "\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 35/50 [00:23<00:17,  1.16s/it]\n",
      "\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 36/50 [00:23<00:13,  1.03it/s]\n",
      "\n",
      " 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 37/50 [00:24<00:12,  1.00it/s]\n",
      "\n",
      " 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 38/50 [00:24<00:09,  1.29it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 39/50 [00:27<00:13,  1.20s/it]\n",
      "\n",
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                 | 40/50 [00:27<00:10,  1.00s/it]\n",
      "\n",
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                              | 41/50 [00:29<00:11,  1.33s/it]\n",
      "\n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                           | 42/50 [00:31<00:12,  1.51s/it]\n",
      "\n",
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                       | 43/50 [00:31<00:07,  1.10s/it]\n",
      "\n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 44/50 [00:32<00:05,  1.08it/s]\n",
      "\n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 45/50 [00:32<00:03,  1.30it/s]\n",
      "\n",
      " 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 46/50 [00:33<00:02,  1.43it/s]\n",
      "\n",
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 47/50 [00:33<00:02,  1.48it/s]\n",
      "\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 48/50 [00:34<00:01,  1.71it/s]\n",
      "\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 49/50 [00:36<00:00,  1.04it/s]\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:36<00:00,  1.17it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "sample_data_path = './samples'\n",
    "sample_files = [file for file in os.listdir(sample_data_path) if not file.endswith('-tokenized.txt')]\n",
    "final_results = {}\n",
    "for file in sample_files:\n",
    "    with open(os.path.join(sample_data_path, file), 'r', encoding='utf8') as fp:\n",
    "        sentences = fp.read().splitlines()\n",
    "    scores = []\n",
    "    print(file)\n",
    "    for i, sentence in enumerate(tqdm(sentences[:50])):\n",
    "        try:\n",
    "            score = compute_sentence_pseudo_perplexity(sentence.replace('\\xa0 ', ''))\n",
    "            scores.append(score)\n",
    "        except Exception as e:\n",
    "            scores.append(np.mean(scores))\n",
    "            print(\"Error:\", sentence)\n",
    "            print(e)\n",
    "            pass\n",
    "    \n",
    "    final_results[file] = scores\n",
    "    \n",
    "#with open('/project/RDS-FASS-NKBert-RW/samples/final_scores.pkl', 'wb') as fp:\n",
    "#    pickle.dump(final_results, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Canonical Novels.txt</th>\n",
       "      <th>Central News Agency.txt</th>\n",
       "      <th>Poetry.txt</th>\n",
       "      <th>Prestigious Novels.txt</th>\n",
       "      <th>Regular Novels.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.209670</td>\n",
       "      <td>2.443955</td>\n",
       "      <td>1.223542</td>\n",
       "      <td>1.144097</td>\n",
       "      <td>1.203318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.204206</td>\n",
       "      <td>1.389317</td>\n",
       "      <td>1.230228</td>\n",
       "      <td>1.272423</td>\n",
       "      <td>1.169514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.380719</td>\n",
       "      <td>1.669474</td>\n",
       "      <td>1.398089</td>\n",
       "      <td>1.417424</td>\n",
       "      <td>1.126534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.181183</td>\n",
       "      <td>1.597755</td>\n",
       "      <td>1.092810</td>\n",
       "      <td>1.275422</td>\n",
       "      <td>1.282778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.156280</td>\n",
       "      <td>1.525260</td>\n",
       "      <td>1.395509</td>\n",
       "      <td>1.217113</td>\n",
       "      <td>1.192590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.297239</td>\n",
       "      <td>1.491886</td>\n",
       "      <td>1.230329</td>\n",
       "      <td>1.118591</td>\n",
       "      <td>1.463237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.164006</td>\n",
       "      <td>1.573723</td>\n",
       "      <td>2.139622</td>\n",
       "      <td>1.159269</td>\n",
       "      <td>1.103083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.200825</td>\n",
       "      <td>1.849308</td>\n",
       "      <td>1.759736</td>\n",
       "      <td>1.183096</td>\n",
       "      <td>1.241275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.203097</td>\n",
       "      <td>1.176762</td>\n",
       "      <td>1.333625</td>\n",
       "      <td>1.148951</td>\n",
       "      <td>1.180546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.157497</td>\n",
       "      <td>1.377148</td>\n",
       "      <td>1.378277</td>\n",
       "      <td>1.207022</td>\n",
       "      <td>1.222851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.270267</td>\n",
       "      <td>1.601829</td>\n",
       "      <td>1.137598</td>\n",
       "      <td>1.172457</td>\n",
       "      <td>1.221899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.254985</td>\n",
       "      <td>1.161010</td>\n",
       "      <td>1.213835</td>\n",
       "      <td>1.204455</td>\n",
       "      <td>1.206559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.225866</td>\n",
       "      <td>1.664534</td>\n",
       "      <td>1.150371</td>\n",
       "      <td>1.221134</td>\n",
       "      <td>1.191777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.499066</td>\n",
       "      <td>1.386479</td>\n",
       "      <td>1.203948</td>\n",
       "      <td>1.143197</td>\n",
       "      <td>1.118472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.410691</td>\n",
       "      <td>1.338673</td>\n",
       "      <td>1.352884</td>\n",
       "      <td>1.211795</td>\n",
       "      <td>1.187539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.218874</td>\n",
       "      <td>1.252846</td>\n",
       "      <td>1.604153</td>\n",
       "      <td>1.213459</td>\n",
       "      <td>1.232778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.243038</td>\n",
       "      <td>1.341940</td>\n",
       "      <td>1.190307</td>\n",
       "      <td>1.126122</td>\n",
       "      <td>1.305193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.196191</td>\n",
       "      <td>1.462131</td>\n",
       "      <td>1.457858</td>\n",
       "      <td>1.252358</td>\n",
       "      <td>1.249007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.357639</td>\n",
       "      <td>2.257934</td>\n",
       "      <td>2.039397</td>\n",
       "      <td>1.236355</td>\n",
       "      <td>1.162903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.243385</td>\n",
       "      <td>1.498420</td>\n",
       "      <td>1.448195</td>\n",
       "      <td>1.228704</td>\n",
       "      <td>1.197745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.174329</td>\n",
       "      <td>1.579628</td>\n",
       "      <td>1.712177</td>\n",
       "      <td>1.160970</td>\n",
       "      <td>1.328518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.178695</td>\n",
       "      <td>1.798208</td>\n",
       "      <td>1.499243</td>\n",
       "      <td>1.122415</td>\n",
       "      <td>1.267933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.480652</td>\n",
       "      <td>2.110722</td>\n",
       "      <td>1.165332</td>\n",
       "      <td>1.214364</td>\n",
       "      <td>1.611309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.193403</td>\n",
       "      <td>1.548586</td>\n",
       "      <td>1.129442</td>\n",
       "      <td>1.159127</td>\n",
       "      <td>1.234010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.193413</td>\n",
       "      <td>1.269398</td>\n",
       "      <td>1.146040</td>\n",
       "      <td>1.188844</td>\n",
       "      <td>1.549132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.212394</td>\n",
       "      <td>1.300802</td>\n",
       "      <td>1.296924</td>\n",
       "      <td>1.184055</td>\n",
       "      <td>1.143474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.502687</td>\n",
       "      <td>1.296805</td>\n",
       "      <td>1.174815</td>\n",
       "      <td>1.186263</td>\n",
       "      <td>1.300657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.223512</td>\n",
       "      <td>2.066184</td>\n",
       "      <td>1.188326</td>\n",
       "      <td>1.357921</td>\n",
       "      <td>1.190408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.268274</td>\n",
       "      <td>1.290813</td>\n",
       "      <td>1.170507</td>\n",
       "      <td>1.295420</td>\n",
       "      <td>1.368183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.192238</td>\n",
       "      <td>1.238954</td>\n",
       "      <td>1.136636</td>\n",
       "      <td>1.192616</td>\n",
       "      <td>1.163047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.201083</td>\n",
       "      <td>1.372751</td>\n",
       "      <td>1.167329</td>\n",
       "      <td>1.155180</td>\n",
       "      <td>1.140902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.323490</td>\n",
       "      <td>1.530962</td>\n",
       "      <td>1.528244</td>\n",
       "      <td>1.174264</td>\n",
       "      <td>1.512208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.171755</td>\n",
       "      <td>1.284772</td>\n",
       "      <td>1.347916</td>\n",
       "      <td>1.265297</td>\n",
       "      <td>1.203260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.234526</td>\n",
       "      <td>1.183468</td>\n",
       "      <td>1.311147</td>\n",
       "      <td>1.125954</td>\n",
       "      <td>1.394500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.233717</td>\n",
       "      <td>1.262362</td>\n",
       "      <td>1.147027</td>\n",
       "      <td>1.184469</td>\n",
       "      <td>1.256720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.272845</td>\n",
       "      <td>1.506372</td>\n",
       "      <td>1.185039</td>\n",
       "      <td>1.171192</td>\n",
       "      <td>1.215392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.233828</td>\n",
       "      <td>1.656656</td>\n",
       "      <td>1.111886</td>\n",
       "      <td>1.194076</td>\n",
       "      <td>1.170352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.191604</td>\n",
       "      <td>1.378469</td>\n",
       "      <td>1.192725</td>\n",
       "      <td>1.265497</td>\n",
       "      <td>1.199716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.191296</td>\n",
       "      <td>1.333905</td>\n",
       "      <td>1.145627</td>\n",
       "      <td>1.201230</td>\n",
       "      <td>1.181181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.218331</td>\n",
       "      <td>1.399206</td>\n",
       "      <td>1.150874</td>\n",
       "      <td>1.231969</td>\n",
       "      <td>1.292043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.272506</td>\n",
       "      <td>1.858224</td>\n",
       "      <td>1.209229</td>\n",
       "      <td>1.138478</td>\n",
       "      <td>1.231426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.247415</td>\n",
       "      <td>1.487616</td>\n",
       "      <td>1.145868</td>\n",
       "      <td>1.150757</td>\n",
       "      <td>1.188799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.310818</td>\n",
       "      <td>2.161792</td>\n",
       "      <td>1.490132</td>\n",
       "      <td>1.210011</td>\n",
       "      <td>1.141013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.167676</td>\n",
       "      <td>1.396593</td>\n",
       "      <td>1.134320</td>\n",
       "      <td>1.188384</td>\n",
       "      <td>1.536108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.291242</td>\n",
       "      <td>1.703151</td>\n",
       "      <td>1.918278</td>\n",
       "      <td>1.149444</td>\n",
       "      <td>1.146609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.146142</td>\n",
       "      <td>1.387383</td>\n",
       "      <td>1.490194</td>\n",
       "      <td>1.162584</td>\n",
       "      <td>1.206654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.179161</td>\n",
       "      <td>1.723710</td>\n",
       "      <td>1.879028</td>\n",
       "      <td>1.140880</td>\n",
       "      <td>1.249621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.329991</td>\n",
       "      <td>1.529871</td>\n",
       "      <td>1.271232</td>\n",
       "      <td>1.492582</td>\n",
       "      <td>1.161872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.309255</td>\n",
       "      <td>1.504160</td>\n",
       "      <td>1.970120</td>\n",
       "      <td>1.216038</td>\n",
       "      <td>1.164586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.183017</td>\n",
       "      <td>1.318071</td>\n",
       "      <td>1.088287</td>\n",
       "      <td>1.242843</td>\n",
       "      <td>1.160874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Canonical Novels.txt  Central News Agency.txt  Poetry.txt  \\\n",
       "0               1.209670                 2.443955    1.223542   \n",
       "1               1.204206                 1.389317    1.230228   \n",
       "2               1.380719                 1.669474    1.398089   \n",
       "3               1.181183                 1.597755    1.092810   \n",
       "4               1.156280                 1.525260    1.395509   \n",
       "5               1.297239                 1.491886    1.230329   \n",
       "6               1.164006                 1.573723    2.139622   \n",
       "7               1.200825                 1.849308    1.759736   \n",
       "8               1.203097                 1.176762    1.333625   \n",
       "9               1.157497                 1.377148    1.378277   \n",
       "10              1.270267                 1.601829    1.137598   \n",
       "11              1.254985                 1.161010    1.213835   \n",
       "12              1.225866                 1.664534    1.150371   \n",
       "13              1.499066                 1.386479    1.203948   \n",
       "14              1.410691                 1.338673    1.352884   \n",
       "15              1.218874                 1.252846    1.604153   \n",
       "16              1.243038                 1.341940    1.190307   \n",
       "17              1.196191                 1.462131    1.457858   \n",
       "18              4.357639                 2.257934    2.039397   \n",
       "19              1.243385                 1.498420    1.448195   \n",
       "20              1.174329                 1.579628    1.712177   \n",
       "21              1.178695                 1.798208    1.499243   \n",
       "22              1.480652                 2.110722    1.165332   \n",
       "23              1.193403                 1.548586    1.129442   \n",
       "24              1.193413                 1.269398    1.146040   \n",
       "25              1.212394                 1.300802    1.296924   \n",
       "26              1.502687                 1.296805    1.174815   \n",
       "27              1.223512                 2.066184    1.188326   \n",
       "28              1.268274                 1.290813    1.170507   \n",
       "29              1.192238                 1.238954    1.136636   \n",
       "30              1.201083                 1.372751    1.167329   \n",
       "31              1.323490                 1.530962    1.528244   \n",
       "32              1.171755                 1.284772    1.347916   \n",
       "33              1.234526                 1.183468    1.311147   \n",
       "34              1.233717                 1.262362    1.147027   \n",
       "35              1.272845                 1.506372    1.185039   \n",
       "36              1.233828                 1.656656    1.111886   \n",
       "37              1.191604                 1.378469    1.192725   \n",
       "38              1.191296                 1.333905    1.145627   \n",
       "39              1.218331                 1.399206    1.150874   \n",
       "40              1.272506                 1.858224    1.209229   \n",
       "41              1.247415                 1.487616    1.145868   \n",
       "42              1.310818                 2.161792    1.490132   \n",
       "43              1.167676                 1.396593    1.134320   \n",
       "44              1.291242                 1.703151    1.918278   \n",
       "45              1.146142                 1.387383    1.490194   \n",
       "46              1.179161                 1.723710    1.879028   \n",
       "47              1.329991                 1.529871    1.271232   \n",
       "48              1.309255                 1.504160    1.970120   \n",
       "49              1.183017                 1.318071    1.088287   \n",
       "\n",
       "    Prestigious Novels.txt  Regular Novels.txt  \n",
       "0                 1.144097            1.203318  \n",
       "1                 1.272423            1.169514  \n",
       "2                 1.417424            1.126534  \n",
       "3                 1.275422            1.282778  \n",
       "4                 1.217113            1.192590  \n",
       "5                 1.118591            1.463237  \n",
       "6                 1.159269            1.103083  \n",
       "7                 1.183096            1.241275  \n",
       "8                 1.148951            1.180546  \n",
       "9                 1.207022            1.222851  \n",
       "10                1.172457            1.221899  \n",
       "11                1.204455            1.206559  \n",
       "12                1.221134            1.191777  \n",
       "13                1.143197            1.118472  \n",
       "14                1.211795            1.187539  \n",
       "15                1.213459            1.232778  \n",
       "16                1.126122            1.305193  \n",
       "17                1.252358            1.249007  \n",
       "18                1.236355            1.162903  \n",
       "19                1.228704            1.197745  \n",
       "20                1.160970            1.328518  \n",
       "21                1.122415            1.267933  \n",
       "22                1.214364            1.611309  \n",
       "23                1.159127            1.234010  \n",
       "24                1.188844            1.549132  \n",
       "25                1.184055            1.143474  \n",
       "26                1.186263            1.300657  \n",
       "27                1.357921            1.190408  \n",
       "28                1.295420            1.368183  \n",
       "29                1.192616            1.163047  \n",
       "30                1.155180            1.140902  \n",
       "31                1.174264            1.512208  \n",
       "32                1.265297            1.203260  \n",
       "33                1.125954            1.394500  \n",
       "34                1.184469            1.256720  \n",
       "35                1.171192            1.215392  \n",
       "36                1.194076            1.170352  \n",
       "37                1.265497            1.199716  \n",
       "38                1.201230            1.181181  \n",
       "39                1.231969            1.292043  \n",
       "40                1.138478            1.231426  \n",
       "41                1.150757            1.188799  \n",
       "42                1.210011            1.141013  \n",
       "43                1.188384            1.536108  \n",
       "44                1.149444            1.146609  \n",
       "45                1.162584            1.206654  \n",
       "46                1.140880            1.249621  \n",
       "47                1.492582            1.161872  \n",
       "48                1.216038            1.164586  \n",
       "49                1.242843            1.160874  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(final_results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x220b6a81bc8>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df.boxplot(figsize = (20, 10), showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Canonical Novels.txt</th>\n",
       "      <th>Central News Agency.txt</th>\n",
       "      <th>Poetry.txt</th>\n",
       "      <th>Prestigious Novels.txt</th>\n",
       "      <th>Regular Novels.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.308080</td>\n",
       "      <td>1.530800</td>\n",
       "      <td>1.349685</td>\n",
       "      <td>1.205531</td>\n",
       "      <td>1.243402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.448233</td>\n",
       "      <td>0.287307</td>\n",
       "      <td>0.268844</td>\n",
       "      <td>0.071565</td>\n",
       "      <td>0.115989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.146142</td>\n",
       "      <td>1.161010</td>\n",
       "      <td>1.088287</td>\n",
       "      <td>1.118591</td>\n",
       "      <td>1.103083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.191763</td>\n",
       "      <td>1.335097</td>\n",
       "      <td>1.154488</td>\n",
       "      <td>1.159163</td>\n",
       "      <td>1.169723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.221193</td>\n",
       "      <td>1.489751</td>\n",
       "      <td>1.226885</td>\n",
       "      <td>1.190730</td>\n",
       "      <td>1.204939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.272760</td>\n",
       "      <td>1.642949</td>\n",
       "      <td>1.455443</td>\n",
       "      <td>1.226811</td>\n",
       "      <td>1.265130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.357639</td>\n",
       "      <td>2.443955</td>\n",
       "      <td>2.139622</td>\n",
       "      <td>1.492582</td>\n",
       "      <td>1.611309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Canonical Novels.txt  Central News Agency.txt  Poetry.txt  \\\n",
       "count             50.000000                50.000000   50.000000   \n",
       "mean               1.308080                 1.530800    1.349685   \n",
       "std                0.448233                 0.287307    0.268844   \n",
       "min                1.146142                 1.161010    1.088287   \n",
       "25%                1.191763                 1.335097    1.154488   \n",
       "50%                1.221193                 1.489751    1.226885   \n",
       "75%                1.272760                 1.642949    1.455443   \n",
       "max                4.357639                 2.443955    2.139622   \n",
       "\n",
       "       Prestigious Novels.txt  Regular Novels.txt  \n",
       "count               50.000000           50.000000  \n",
       "mean                 1.205531            1.243402  \n",
       "std                  0.071565            0.115989  \n",
       "min                  1.118591            1.103083  \n",
       "25%                  1.159163            1.169723  \n",
       "50%                  1.190730            1.204939  \n",
       "75%                  1.226811            1.265130  \n",
       "max                  1.492582            1.611309  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonical Novels.txt : Central News Agency.txt\n",
      "Ttest_indResult(statistic=-2.9579997457226885, pvalue=0.003881129522025585)\n",
      "Canonical Novels.txt : Poetry.txt\n",
      "Ttest_indResult(statistic=-0.5628541196018756, pvalue=0.5748196413565754)\n",
      "Canonical Novels.txt : Prestigious Novels.txt\n",
      "Ttest_indResult(statistic=1.5975222674962843, pvalue=0.1133688868229852)\n",
      "Canonical Novels.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=0.9877917520701538, pvalue=0.32568723169518554)\n",
      "Central News Agency.txt : Poetry.txt\n",
      "Ttest_indResult(statistic=3.2547756350509465, pvalue=0.001558256756005034)\n",
      "Central News Agency.txt : Prestigious Novels.txt\n",
      "Ttest_indResult(statistic=7.7679914880486525, pvalue=7.903581629017174e-12)\n",
      "Central News Agency.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=6.558962616807905, pvalue=2.5642122730744175e-09)\n",
      "Poetry.txt : Prestigious Novels.txt\n",
      "Ttest_indResult(statistic=3.6639089351593803, pvalue=0.0004031278556707008)\n",
      "Poetry.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=2.5667383647533133, pvalue=0.011778717251121484)\n",
      "Prestigious Novels.txt : Regular Novels.txt\n",
      "Ttest_indResult(statistic=-1.9648354248083697, pvalue=0.05226487387267223)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "for a, b in list(combinations(df.columns, 2)):\n",
    "    print(f'{a} : {b}')\n",
    "    print(stats.ttest_ind(df[a],df[b]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
